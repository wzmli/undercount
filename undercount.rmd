---
title: "Evaluating undercounts in epidemics"
output:
  pdf_document
date: "`r format(Sys.Date(), '%d %B %Y')`"
author: "Michael Li, Jonathan Dushoff, David J. D. Earn, and Ben Bolker"
bibliography: undercount.bib
csl: nature.csl 
header-includes:
  - \usepackage[utf8]{inputenc}
  - \usepackage{grffile}
urlcolor: blue
---

## Introduction

Several papers [@bohningEstimating2020; @maruottiEstimating2022; @rocchettiEstimating2020] have promoted formulas that claim to provide bounds on the completeness of sampling of infectious disease cases, based only on case reports. We believe these approaches are fundamentally wrong, and that it is impossible to estimate undercounting without a specialized sampling design or some kind of auxiliary information.

The authors' basic idea uses formulas developed by Chao to estimate bounds on true population sizes based on the numbers of individuals observed multiple times. For example, their estimator for the lower bound on true cases is $\Delta N(t) (\Delta N(t) - 1)/(1 + \Delta N(t-1))$, where $\Delta N(t)$ is the number of new cases observed per reporting period; an extended formula adjusts for mortality. The upper bound also involves $\Delta N(t-2)$ [@bohningEstimating2020; @rocchettiEstimating2020].

## Critique

This approach misuses the mark-recapture formulas. Cases identified at time $t-1$ are supposed to be representative of the number of cases counted twice: why? The fact that the same individual *could* be counted twice in the cumulative case report (for some sampling designs) is irrelevant. How can comparing yesterday's count to today's provide information about the completeness of sampling? 

In principle, the number of unobserved individuals (hidden cases) can be estimated if individuals can be re-identified, or even with unmarked individuals given an appropriate sampling design [@royleHierarchical2008]. 
In practice public health case reporting rarely uses such sampling designs. Case reporting is usually exclusive (i.e. someone who has been identified as a case will not be reported again later), or anonymized so that we cannot identify a particular infected individual as double-counted. Mark-recapture methods are sometimes used in public health, but "one needs at least two sources of information with individual case reporting and a unique personal identifier for each case" [@desenclosLimitations1994].

### Exponential example

During the initial phase of an epidemic, various measures of current epidemic size (incidence, cumulative incidence, etc.) all grow geometrically. Suppose the incidence (true number of new infections: $I(t)$) grows at a rate $\lambda$ per time step, i.e. $I(t) = I(0) \lambda^t$, and suppose a fraction $a$ (the *ascertainment ratio*) of these cases are reported. The estimated ascertainment ratio $\hat a$ equals the number of reported cases, divided by the total number of estimated cases, i.e. (reported cases + estimated hidden cases). Using the simpler, non-bias-corrected formula:

$$
\begin{split}
\hat a & = \frac{\Delta N(t)}{\Delta N(t) + H(t)} \\
& = \frac{\Delta N(t)}{\Delta N(t) + \frac{[\Delta N(t)]^2}{\Delta N(t - 1)}} \\
& = \left(1 + \Delta N(t)/\Delta N(t-1)\right) \\
& = \left(1 + a I(0) \lambda^t/(a I(0) \lambda^{t-1}\right) \\
& = 1/(1+\lambda).
\end{split}
$$

The estimated ascertainment ratio $\hat a$ depends only on the epidemic growth rate; it is independent of the true ascertainment ratio.  The bias-corrected formula, which we use in our simulations below, has similar problems.

More generally, we can see that the estimate of underreporting will always be equal to the rate of acceleration of observed cases ($\Delta N(t)/\Delta N(t-1)$) times the number of new cases $\Delta N(t)$, so underreporting (proportional to observed cases) will be assumed to be larger when disease incidence is increasing, and smaller when it is decreasing.

### Simulation example (SIR model)

```{r get_pars, echo=FALSE}
library(shellpipes)
loadEnvironments()
options(digits = 2)
pct <- function(x) round(100*x)
R0  <- round(beta/gamma,2)
inf_per <- round(1/gamma,2)
getstat <- function(scenario, stat, rnd = 3) round(summ[summ$Scenario == scenario, stat], rnd)
rProp <- c(high = as.numeric(getstat("high", "reportProp")), low = as.numeric(getstat("low", "reportProp")))
true_frac <- (1-rProp)/rProp
```

We simulated a discrete-time deterministic SIR epidemic, applied two different ascertainment ratios ($a = \{0.2, 0.8\}$) to derive time series of case reports, and used the `asymptor` package [@grusonAsymptor2020] (which computes bounds incorporating bias corrections) to estimate hidden cases (Figure 1).
The estimated lower and upper bounds are largely independent of the true $a$; at the beginning and end of the epidemic, when the absolute number of cases is lower, the bias correction terms make the estimated bounds on the ascertainment ratio *higher* in the low-ascertainment scenario and *vice versa*.

<!-- note N is hard-coded, too hard to format nicely/automatically -->
```{r get_plot, echo = FALSE, out.height = "4in", fig.cap = sprintf('Estimates based on a simulated SIR epidemic with ${\\cal R}_0 = %1.1f$, infectious period of %1.2f days, $N = 10^6$. Left panel, true numbers of hidden cases (lines) with estimated bounds (regions). Right panel, true ascertainment ratios (lines) and estimated bounds (regions).', R0, inf_per)}
knitr::include_graphics(matchFile(exts="pdf"))
```

### Simulation example (Richards curve)

We ran additional simulations using a Richards curve for the cumulative incidence of the epidemic [@maEstimating2014]. We computed expected incidence by differencing the cumulative incidence, drew a random negative binomial deviate with this mean, and used a binomial sample with probability equal to the ascertainment ratio $a$ to get the number of observed cases. Throughout, we used a shape parameter of $s=2$ and a final epidemic size of $10^5$ for the Richards curve, and a negative binomial dispersion parameter $k=5$. We varied the reporting period ($\Delta t = \{1, 7\}$); starting incidence ($I_0 = \{20, 40\}$); epidemic growth rate ($r$ =  0.01 to 0.08 per day); and ascertainment ratio ($a$ from 0.05 to 0.6). We ran each simulation for 100 days and used `asymptor` to compute bounds on the ascertainment ratio.

The authors indicated (pers. comm.) that they intended the estimator to be used at the beginning of an epidemic. Therefore we considered only sample points when the number of cases was between 5 and 500 (exclusive) and the lower bound estimator for hidden cases was greater than 1.

For each simulation run (80 in total), we computed the mean and confidence intervals for the estimated lower and upper bounds of $\hat a$ over time (Figure 2). As suggested by our SIR example, the bounds on $\hat a$ rarely included the true value, and were *largely independent of the true values of $a$*. The only noticeable signal arises from the bias-correction terms: simulations with lower overall case numbers (low $r$, low $a$, $\Delta t = 1$) have noticeably lower upper bounds and slightly greater lower bounds. Analyzing simulations without noise and with the simpler, non-bias-corrected expression for the lower bound (not shown), the estimated lower bound ratio during the exponential phase of the epidemic exactly equals the discrete-time growth rate ($\lambda = \exp(r\Delta t)$); these estimates are completely independent of the ascertainment ratio, and indeed of any parameters other than the epidemic growth rate.

```{r fig.cap="Ratio of lower/upper bounds to observed cases. $\\Delta t = 1$, $I(0)=40$ (results are similar for other choices of $\\Delta t$ and $I(0)$). Left-hand axis shows ratios of bounds to observed cases; right-hand axis shows the estimated ascertainment ratio ($1/(1+\\textrm{bounds ratio})$). Dashed line is the one-to-one line.", echo = FALSE}
knitr::include_graphics("a_plot.pdf")
```

We conclude that the authors' formula appears to work well because it leads to plausible bounds on the ascertainment ratio (0.2 -- 0.5) for realistic values of the epidemic growth rate, but that it is in fact nearly unrelated to the true ascertainment ratio and should not be applied to disease outbreak incidence data.

\newpage

## References

