---
title: "Evaluating undercounts in epidemics"
output:
  pdf_document
date: "`r format(Sys.Date(), '%d %B %Y')`"
author: "Michael Li, Jonathan Dushoff, David J. D. Earn, and Ben Bolker"
bibliography: undercount.bib
header-includes:
  - \usepackage[utf8]{inputenc}
  - \usepackage{grffile}
csl: nature.csl 
urlcolor: blue
---

## Introduction

Several papers [@bohningEstimating2020; @maruottiEstimating2022; @rocchettiEstimating2020] have promoted formulas that claim to provide bounds on the completeness of sampling of infectious disease cases, based only on case reports. We believe these approaches are fundamentally wrong, and that it is impossible to estimate undercounting without a specialized sampling design or some kind of auxiliary information.

The basic idea is to use formulas developed by Chao to estimate bounds on true population sizes based on the numbers of individuals observed multiple times. The basic estimator for the lower bound on true cases is $\Delta N(t) (\Delta N(t) - 1)/(1 + \Delta N(t-1))$, where $\Delta N(t)$ is the number of new cases observed per reporting period; an extension to the formula adjusts for mortality. The upper bound also involves $\Delta N(t-2)$ [@bohningEstimating2020; @rocchettiEstimating2020].

## Critique

This approach misuses the mark-recapture formulas. Cases identified at time $t-1$ are supposed to be representative of the number of cases counted twice: why? The fact that the same individual *could* be counted twice in the cumulative case report (for some sampling designs) is irrelevant. How can comparing yesterday's count to today's provide information about the completeness of sampling? 

In principle, the number of unobserved individuals (hidden cases) can be estimated if individuals can be re-identified when observed a second time, or even with unmarked individuals given an appropriate sampling design [@royleHierarchical2008]. 
In practice public health case reporting rarely uses such sampling designs. Case reporting is usually exclusive (i.e. someone who has been identified as a case will not be reported again later) and/or anonymized so that we cannot identify whether a particular infected individual was double-counted or not. Mark-recapture methods are sometimes used in public health, but "one needs at least two sources of information with individual case reporting and a unique personal identifier for each case" [@desenclosLimitations1994].

### Exponential example

During the initial phase of an epidemic, various measures of current epidemic size (incidence, cumulative incidence, etc.) all grow geometrically. Suppose the incidence (true number of new infections: $I(t)$) grows at a rate $\lambda$ per time step, i.e. $I(t) = I(0) \lambda^t$, and suppose a fraction $a$ (the *ascertainment ratio*) of these cases are reported. The estimated ascertainment ratio $\hat a$ equals the number of reported cases, divided by the total number of estimated cases, i.e. (reported cases + estimated hidden cases). Using the simpler, non-bias-corrected formula:

$$
\begin{split}
\hat a & = \frac{\Delta N(t)}{\Delta N(t) + H(t)} \\
& = \frac{\Delta N(t)}{\Delta N(t) + \frac{[\Delta N(t)]^2}{\Delta N(t - 1)}} \\
& = \left(1 + \Delta N(t)/\Delta N(t-1)\right) \\
& = \left(1 + a I(0) \lambda^t/(a I(0) \lambda^{t-1}\right) \\
& = 1/(1+\lambda).
\end{split}
$$

The estimated ascertainment ratio $\hat a$ depends only on the epidemic growth rate; it is independent of the true ascertainment ratio.  The bias-corrected formula, which we use in our simulations below, has similar problems.

More generally, we can see that the estimate of underreporting will always be equal to the rate of acceleration of observed cases ($\Delta N(t)/\Delta N(t-1)$) times the number of new cases $\Delta N(t)$, so underreporting (proportional to observed cases) will be assumed to be larger when disease incidence is increasing, and smaller when it is decreasing.

### Simulation example (SIR model)

```{r get_pars, echo=FALSE}
library(shellpipes)
loadEnvironments()
options(digits = 2)
pct <- function(x) round(100*x)
R0  <- round(beta/gamma,2)
inf_per <- round(1/gamma,2)
getstat <- function(scenario, stat, rnd = 3) round(summ[summ$Scenario == scenario, stat], rnd)
rProp <- c(high = as.numeric(getstat("high", "reportProp")), low = as.numeric(getstat("low", "reportProp")))
true_frac <- (1-rProp)/rProp
```

We simulate a deterministic SIR epidemic in discrete time, apply two different ascertainment ratios to derive a time series of case reports, and apply the authors' formula (including bias corrections) to estimate the number of hidden cases (Figure 1).
At the peak of the epidemic, when the number of cases is large, the method predicts the same ratio of hidden cases to observed case reports regardless of the ascertainment fraction; at the beginning and end of the epidemic, the bias correction terms make underreporting appear lower in the lower-ascertainment scenario, when the number of reported cases is lower. In the high-ascertainment case ($a = `r rProp[["high"]]`$) the true ratio of hidden to reported cases is `r true_frac[["high"]]`, but the average estimated ratio is `r getstat("high", "mean")` (range `r getstat("high", "min")` -- `r getstat("high", "max")`); in the low-ascertainment case ($a = `r rProp[["low"]]`$) the true ratio is `r true_frac[["low"]]` and the mean estimate is `r getstat("low", "mean")` (range `r getstat("low", "min")` -- `r getstat("low", "max")`).

<!-- note N is hard-coded, too hard to format nicely/automatically -->
```{r get_plot, echo = FALSE, out.height = "4in", fig.cap = sprintf('Estimates based on a simulated SIR epidemic with ${\\cal R}_0 = %1.1f$, infectious period of %1.2f days, $N = 10^6$. Left panel, true numbers of hidden cases (lines) with estimated bounds (regions). Right panel, true ascertainment ratios (lines) and estimated bounds (regions).', R0, inf_per)}
knitr::include_graphics(matchFile(exts="pdf"))
```

## Simulation example (Richards equation)

Based on correspondence with one of the authors of the original papers, we ran an additional set of simulations that used a Richards curve to model the cumulative growth of the epidemic [@maEstimating2014]. (We reparameterized the model using the initial incidence, i.e. the derivative of the curve at $t=0$, rather than the inflection point parameter $t_{\textrm{infl}}$.) We then computed the incidence by differencing the cumulative incidence, and used the ascertainment ratio $a$ to get the number of hidden cases and observed cases (multiplying by $1-a$ and $a$ respectively). Throughout, we used a shape parameter of $s=2$ and a final epidemic size of $10^5$; we varied the reporting period ($\Delta t = \{1, 7\}$); starting incidence ($I_0 = \{20, 40\}$); epidemic growth rate ($r = \{ 0.01, 0.02, 0.04, 0.08\}$ per day); and ascertainment ratio ($a = \{0.05, 0.1, 0.2, 0.4, 0.6\}$). We ran each simulation for 100 days. We used the `asymptor` package [@grusonAsymptor2020], which implements the lower-bound formula from @bohningEstimating2020 and the upper-bound formula from @rocchettiEstimating2020, as an independent check to make sure we had not incorrectly coded any of the formulas. 

The authors indicated (pers. comm.) that they intended the estimator to be used at the beginning of an epidemic. To make sure that we were only computing bounds during reasonable times, we restricted our conclusions to periods when the number of cases was between 5 and 500 (exclusive) and when the lower bound estimator was greater than 1.

We ran deterministic simulations, to simplify comparisons. While omitting noise is unrealistic, adding (e.g.) negative binomial error for incidence and/or binomial error for ascertainment would not change any of our qualitative conclusions.

For each of the simulation runs (80 in total), we first evaluated whether the number of hidden cases estimated by `asymptor` in fact remained within the computed upper and lower bounds (Figure 2). Regardless of reporting period and initial incidence, the method always underestimated the number of hidden cases (i.e., the true number of hidden cases was above the estimated upper bound for at least one time period) when the ascertainment ratio was low ($a$ from 0.05 to 0.2) and overestimated the number of hidden cases (the true number of hidden cases was below the lower bound for at least one time period) when the ascertainment ratio was high ($a=0.6$).

If we instead examine the estimated upper and lower bounds scaled by number of reported cases (Figure 3), we see that the scaled bounds are always between about 1 and 3. These values correspond to lower bounds on the ascertainment ratio of 0.2 to 0.25 and upper bounds of 0.5 to 0.6, *largely independent of the true values of the ascertainment ratio*. (In fact, the estimated lower bound on the ascertainment ratio is lower when the true ascertainment ratio is higher, because more cases are reported overall and thus the bias-correction terms have less effect.)

Checking the simpler, non-bias-corrected expression for the lower bound ($\Delta N(t)^2/\Delta N(t-1)$, not shown) confirms that most of the observed variation in the estimated bounds is driven by the bias-correction terms. When the bias-correction terms are ignored, the estimated lower bound ratio during the early/exponential phase of the epidemic always corresponds to the discrete-time growth rate ($\lambda = \exp(r\Delta t)$); these estimated bounds are completely independent of the ascertainment ratio, and indeed of any parameters other than the epidemic growth rate.

```{r fig.cap="Ratio of lower/upper bounds to observed cases. $\\Delta t = 1$, $I(0)=40$ (results are similar for other choices of $\\Delta t$ and $I(0)$). Left-hand axis shows ratios of bounds to observed cases; right-hand axis shows the estimated ascertainment ratio ($1/(1+\\textrm{bounds ratio})$).", echo = FALSE}
knitr::include_graphics("a_plot.pdf")
```

We conclude that the authors' formula appears to work well because it leads to plausible bounds on the ascertainment ratio (0.25 -- 0.5) for realistic values of the epidemic growth rate, but that it is in fact mostly unrelated to the true ascertainment ratio and should not be applied to disease outbreak incidence data.

\newpage

## References

