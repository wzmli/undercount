---
title: "Evaluating undercounts in epidemics"
output:
  pdf_document
date: "`r format(Sys.Date(), '%d %B %Y')`"
author: "Michael Li, Jonathan Dushoff, David J. D. Earn, and Ben Bolker"
bibliography: undercount.bib
csl: nature.csl 
header-includes:
  - \usepackage[utf8]{inputenc}
  - \usepackage{grffile}
urlcolor: blue
---

## Introduction

Several papers [@bohningEstimating2020; @maruottiEstimating2022; @rocchettiEstimating2020] have promoted formulas that claim to provide bounds on the completeness of sampling of infectious disease cases, based only on case reports. We believe these approaches are fundamentally wrong, and that it is impossible to estimate undercounting from incidence data without a specialized sampling design or some kind of auxiliary information.

The authors' basic idea uses formulas developed by Chao to estimate bounds on true population sizes based on the numbers of individuals observed multiple times. For example, their estimator for the lower bound on true cases is $\Delta N(t) (\Delta N(t) - 1)/(1 + \Delta N(t-1))$, where $\Delta N(t)$ is the number of new cases observed per reporting period; an extended formula adjusts for mortality. The upper bound also involves $\Delta N(t-2)$ [@bohningEstimating2020; @rocchettiEstimating2020].

## Critique

This approach misuses the mark-recapture formulas. Cases identified at time $t-1$ are supposed to be representative of the number of cases counted twice: why? The fact that the same individual *could* be counted twice in the cumulative case report (for some sampling designs) is irrelevant. How can comparing yesterday's count to today's provide information about the completeness of sampling? 

In principle, the number of unobserved individuals (hidden cases) can be estimated if individuals can be re-identified, or even with unmarked individuals given an appropriate sampling design [@royleHierarchical2008]. 
In practice public health case reporting rarely uses such sampling designs. Case reporting is usually exclusive (i.e. someone who has been identified as a case will not be reported again later), or anonymized so that we cannot identify a particular infected individual as double-counted. Mark-recapture methods are sometimes used in public health, but "one needs at least two sources of information with individual case reporting and a unique personal identifier for each case" [@desenclosLimitations1994].

## Simulation example

We ran simulations using a Richards curve for the cumulative incidence of the epidemic [@maEstimating2014]. We computed expected incidence by differencing the cumulative incidence, drew a random negative binomial deviate with this mean, and used a binomial sample with probability equal to the ascertainment ratio $a$ to get the number of observed cases. Throughout, we used a shape parameter of $s=2$ and a final epidemic size of $10^5$ for the Richards curve, and a negative binomial dispersion parameter $k=5$. We varied the reporting period ($\Delta t = \{1, 7\}$); starting incidence ($I_0 = \{20, 40\}$); epidemic growth rate ($r$ =  0.01 to 0.08 per day); and ascertainment ratio ($a$ from 0.05 to 0.6). We ran each simulation for 100 days and used the R package `asymptor` [@grusonAsymptor2020] to compute bounds on the ascertainment ratio.

The authors indicated (pers. comm.) that they intended the estimator to be used at the beginning of an epidemic. Therefore we considered only sample points when the number of cases was between 5 and 500 (exclusive) and the lower bound estimator for hidden cases was greater than 1.

For each simulation run (80 in total), we computed the mean and confidence intervals for the estimated lower and upper bounds of $\hat a$ over time (Figure 1). The bounds on $\hat a$ rarely overlap the true value, and are *largely independent of the true values of $a$*. The only noticeable signal arises from the bias-correction terms: simulations with lower overall case numbers (low $r$, low $a$, $\Delta t = 1$) have larger lower bounds and smaller upper bounds. In simulations without noise and with the simpler, non-bias-corrected expression for the lower bound (not shown), the lower-bound estimates of $\hat a$ are completely independent of $a$; some algebra shows that during the exponential growth phase of an epidemic, the lower bound on $\hat a$ is exactly equal to $1/(1+\exp(r \Delta t))$.

```{r fig.cap="Comparison of true ascertainment ratio ($a$) to estimated lower and upper bounds of ascertainment ratio ($\\hat a$). Dashed line is the one-to-one line (estimated = true).", echo = FALSE}
knitr::include_graphics("a_plot.pdf")
```

We conclude that the authors' formula appears to work well because it leads to plausible bounds on the ascertainment ratio ($\approx$ 0.2 -- 0.5) for realistic values of the epidemic growth rate, but that it is in fact nearly unrelated to the true ascertainment ratio and should not be applied to disease outbreak incidence data.

---

Source code for all examples is available at [https://github.com/wzmli/undercount/](https://github.com/wzmli/undercount/).

## References

