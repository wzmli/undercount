---
title: "Evaluating undercounts in epidemics: response to Maruotti *et al.* 2022"
# date: "`r format(Sys.Date(), '%d %B %Y')`"
#author: "Michael Li, Jonathan Dushoff, David J. D. Earn, and Benjamin M. Bolker"
author:
  - name: Michael Li
    affiliation: "Public Health Agency of Canada"
  - name: Jonathan Dushoff
    affiliation: McMaster University
  - name: David J. D. Earn
    affiliation: McMaster University
  - name: Benjamin M. Bolker
    affiliation: McMaster University
bibliography: undercount.bib
csl: nature.csl 
header-includes:
  - \usepackage[utf8]{inputenc}
  - \usepackage{grffile}
  - \usepackage{amsmath}
urlcolor: blue
output: 
   rticles::arxiv_article:
   keep_tex: true
abstract: Maruotti *et al.* 2022 used a mark-recapture approach to estimate bounds on the true number of monkeypox infections in various countries. We show that such approaches are fundamentally flawed; it is impossible to estimate undercounting based solely on a single stream of reported cases. We give a conceptual argument why this is impossible, and support it with simulations of disease incidence and reporting. The simulations show that the proposed methods estimate bounds on the ascertainment ratio of $\approx 0.2-0.5$ roughly *independently* of the true ascertainment ratio. We conclude that the proposed mark-recapture approach should not be used to estimate undercounting or ascertainment ratios.
---

# Introduction

Several papers [@bohningEstimating2020; @maruottiEstimating2022; @rocchettiEstimating2020] have promoted formulas that claim to provide bounds on the completeness of sampling of infectious disease cases, based only on case reports. We believe these approaches are fundamentally flawed, and that it is impossible to estimate undercounting from incidence data without a specialized sampling design or some kind of auxiliary information.

The authors use mark-recapture formulas developed by Chao [@chaoEstimating1989a] and others [@alfoUpper2021] to estimate bounds on true population sizes based on the numbers of individuals observed multiple times.
For example, the proposed estimator for the lower bound on unobserved individuals (hidden cases) is 
\begin{equation*}
\hat H(t) = \Delta N(t) \frac{\Delta N(t) - 1}{\Delta N(t-1) + 1} \,,
\end{equation*}
where $\Delta N(t)$ is the number of new cases observed per reporting period; extended formulas adjust for mortality and recovery. The upper bound  [@bohningEstimating2020; @rocchettiEstimating2020] also involves $\Delta N(t-2)$.

# Critique

## Conceptual argument

This approach misuses the mark-recapture formulas. Cases identified at time $t-1$ are claimed to be representative of the number of cases counted twice: why? The fact that the same individual *could* be counted twice in the cumulative case report (for some sampling designs) is irrelevant. How can comparing yesterday's count to today's provide information about the completeness of sampling? 

In principle, the number of unobserved (hidden) cases could be estimated if cases can be re-identified, or even with unmarked/unidentified cases given an appropriate sampling design [@royleHierarchical2008]. 
In practice public health case reporting rarely uses such sampling designs. Case reporting is usually exclusive (i.e. someone who has been identified as a case will not be reported again later), or anonymized so that we cannot identify which particular individuals are double-counted because they are infected, and sampled, in two different case-reporting instances.  Mark-recapture methods can provide valuable public health information in specific scenarios such as contact-tracing studies, but "one needs at least two sources of information with individual case reporting and a unique personal identifier for each case" [@desenclosLimitations1994]. This limitation is fundamental to mark-recapture methods; standard case-reporting time series, which do not identifiably re-sample the same individuals, provide no information with which we could estimate the fraction of the population observed.

## Mathematical argument

The simplest mathematical illustration of the problems with the method occurs during the exponential-growth phase of the epidemic (when the authors have suggested that their method is most appropriate). During this phase the incidence (true number of new infections: $I(t)$) grows at a rate $\lambda$ per time step, i.e. $I(t) = I_0 \lambda^t$. Suppose a fraction $a$ (the *ascertainment ratio*) of these cases is reported (i.e. $a$ is the ratio of reported cases to the true incidence; for simplicity we assume here that $a$ is constant over time). An estimated lower bound on the number of hidden cases $\hat H$ can be converted to an upper bound on the estimated ascertainment ratio, $\hat a$. Using the simpler, non-bias-corrected formula:

$$
\begin{split}
\hat a & = \frac{\textrm{observed cases}}{\textrm{observed cases} + \textrm{hidden cases}} \\
& = \frac{\Delta N(t)}{\Delta N(t) + \hat H(t)} \\
& = \frac{\Delta N(t)}{\Delta N(t) + \frac{[\Delta N(t)]^2}{\Delta N(t - 1)}} \\
& = \left(1 + \frac{\Delta N(t)}{\Delta N(t-1)}\right)^{-1} \\
& = \left(1 + \frac{a\,I_0 \lambda^t}{a\,I_0 \lambda^{t-1}}\right)^{-1} \\
& = \frac{1}{1+\lambda} \,.
\end{split}
$$

The estimated upper bound of the ascertainment ratio $\hat a$ thus depends only on the epidemic growth rate; it is independent of the true ascertainment ratio. Furthermore, epidemics typically grow at rates of a few percent per reporting period; an epidemic with more than 20% growth per reporting period ($\lambda > 1.2$) would be catastrophic. Thus, the upper bound on the ascertainment ratio during the exponential phase would typically range only from about 0.45 to 0.5.

Applying a bias correction decreases the lower bound on the number of hidden cases, thus increasing the upper bound on $\hat a$. The results also depend on the overall number of reported cases, so the pattern is more complicated, but as we show below the estimated upper and lower bounds are still largely independent of the true ascertainment ratio.

## Simulation example

We ran simulations using a Richards curve for the cumulative incidence of the epidemic [@maEstimating2014]:
\begin{equation}
\textrm{cumulative incidence}\,(t) = 
\frac{K}{(1 + s\,e^{-s  r (t - h)})^{1 / s}},
\label{eq:richards}
\end{equation}
where $K$ is the final size of the epidemic, $h$ is the time of inflection, and $r$ is the initial growth rate.
The Richards curve is a widely used phenomenological model for epidemic curves [@chowellUsing2016; @mingioneShortterm2022] and, according to the authors, is the same method they used to test their approach  (pers. comm.). We computed expected incidence by differencing the cumulative incidence [@maEstimating2014], drew a random negative binomial deviate with  mean equal to the expected incidence, and used a binomial sample with probability equal to the ascertainment ratio $a$ to get the number of observed cases. Throughout, we used a shape parameter of $s=2$ and a final epidemic size of $10^5$ for the Richards curve, and a negative binomial dispersion parameter $k=5$. We varied the reporting period ($\Delta t = \{1, 7\}$); initial incidence ($I_0 = \{20, 40\}$); epidemic growth rate ($r$ =  0.01 to 0.08 per day); and ascertainment ratio ($a$ from 0.05 to 0.6). (We solved the Richards equation numerically to recover the $h$ parameter given a value of the initial incidence, which is the derivative of (\ref{eq:richards}) at time zero.) These ranges encompass typical parameters of epidemic outbreaks (SARS-CoV-1, COVID-19, monkeypox, etc.), but we argue that the precise numerical values are not very important. The key aspects of a simulation are the epidemic growth rate ($\lambda = \exp(r\Delta t)$), which is the primary determinant of the ascertainment ratio bounds computed according to Maruotti *et al*'s method, and the typical number of cases reported per period, which determines the effects of the bias correction terms.

We ran each simulation for 100 days and used the R package `asymptor` [@grusonAsymptor2020] to compute bounds on the ascertainment ratio. 

The authors indicated (pers. comm.) that they intended the estimator to be used at the beginning of an epidemic. Therefore we considered only sample points when the number of cases was between 5 and 500 (exclusive) and the lower bound estimator for hidden cases was greater than 1.

For each simulation run (80 in total), we computed the mean and confidence intervals for the estimated lower and upper bounds of $\hat a$ over time (Figure 1). The bounds on $\hat a$ rarely overlap the true value, and are *largely independent of the true values of $a$*. The only noticeable signal arises from the bias-correction terms: simulations with lower overall case numbers (low $r$, low $a$, $\Delta t = 1$) have larger lower bounds and smaller upper bounds. The relationship between $\hat a$ and the growth rate $r$ is barely visible as increasing values of the upper bound with $r$ for the cases with $\Delta t = 1$ and low true ascertainment ratio; otherwise, this pattern is swamped by the effects of noise and bias correction. In simulations without noise and with the simpler, non-bias-corrected expression for the lower bound (not shown), the lower-bound estimates of $\hat a$ are completely independent of $a$, as expected from the mathematical argument given above.

```{r aplot,fig.cap="Comparison of true ascertainment ratio ($a$) to estimated lower and upper bounds of ascertainment ratio ($\\hat a$). Dashed line is the one-to-one line (estimated = true).", echo = FALSE, out.width="80%"}
knitr::include_graphics("a_plot.pdf")
```
We conclude that the authors' formulas appear to work well because they lead to plausible bounds on the ascertainment ratio ($\approx$ 0.2 -- 0.5) for realistic values of the epidemic growth rate, but that they are in fact nearly unrelated to the true ascertainment ratio and should not be applied to estimate ascertainment ratios from disease outbreak incidence data.

---

# Data Availability Statement

No data are used in the paper; all code for simulations is available at https://doi.org/10.5281/zenodo.7328063


# Conflict of Interest statement

We declare that none of the authors have conflicts of interest.

# Author contribution statement

All authors contributed to the conceptual development of the paper. ML and BMB wrote computer code for simulations and figures. BMB wrote the first draft of the paper. All authors commented and edited to produce the final version.


## References

